\section{Conclusions}
    In the course of working on the master thesis, I implemented four use case scenarios. The feedback from the various sensors of the two arm \CloPeMa\/ robot is used to accomplish tasks that involve perception and manipulation with soft objects.    

    \subsection{Slingshot}

        \begin{figure}[h]
            \centering
            \begin{tabular}{cc}
            \includegraphics[height=0.3\textwidth]{Img/slingshot/attached_slingshotAdj.png}
            %
            &
            %
            \includegraphics[height=0.3\textwidth]{Img/slingshot/attached_flat_slingshot.png}
            \end{tabular}
            \caption{Left: The traditional slingshot. Right: The flat slingshot.}
            \label{fig:Slingshots}
        \end{figure}

        I designed two slingshots to shoot from -- the so called traditional slingshot (see Figure~\ref{fig:Slingshots}, left side) and the flat slingshot (see Figure~\ref{fig:Slingshots}, right side). Both had to be attached directly to the robot arm. Since the design of the grippers have changed, it was not possible to attach the elastic string directly to it as the projectile could damage some of the sensors placed in the gripper.

        I developed a fully automated shooting procedure that includes loading the projectile, stretching the elastic string to a specified force and adjusting the shooting angle. Thus, a few shots with the same parameters could be shot in a row. The force feedback was used.

        \begin{figure}[h]
        \includegraphics[width=0.5\textwidth]{Img/conclusion/HitTargetAdj.png}
        \centering
        \caption{The projectile hits the target.}
        \label{fig:HitTarget}
        \end{figure}

        I made a few experiments with both slingshots. It involved shooting on a target hanging on the wall and measuring the height, at which the projectile hit the wall. I compared the experimental results with the theoretically calculated values. In case of the traditional slingshot, the results differed a lot. I think it was mainly due to the fact that it was not possible to attach the traditional slingshot tightly to the robot arm. Another reason is for instance the fact that even a small uncertainty in one of the parameters (e.g. the weight of the projectile) influences the theoretical calculation to a high degree. The results concerning the flat slingshot were significantly closer to the theoretical values than in the previous case, yet still not perfect. In order to improve the results, the way the shooting angle is adjusted would have to change.

        Despite the issues stated above, I was able to repeatedly hit the target hanging on the wall (see Figure~\ref{fig:HitTarget}). The success rate was around 50\% for the traditional slingshot and above 90\% for the flat slingshot. I made a video called \textit{TraditionalSlingshot.mpg} featuring the traditional slingshot that shows the whole shooting procedure. It can be found on the attached CD.

        Further work could involve connecting the shooting procedure with an automatic target recognition using for instance the Kinect sensor. The parameters of the shooting such as the shooting angle and the force with which the projectile is shot would then be computed automatically so that the projectile hits the target. In order to achieve such functionality, the slingshot would have to be redesigned further. For instance, the elastic string should be made of a different material so that the force changes gradually with its stretch and not sharply as it is the case of the present elastic string.


    \subsection{Knot-tying}
        I successfully implemented a fully automated knot-tying procedure. I tested the proposed knot-tying sequence on two persons (see Figure~\ref{fig:ABExamples}); one that sees normally (subject A) and one that is blind (subject B). I made conclusions for the robotic knot-tying based on the observed behavior of the two subjects. I especially focused on the blind subject, because his movements resemble in a way the movements of the  \CloPeMa\/ robot more closely than the movements of the normally seeing subject.

        \begin{figure}[h]
            \centering
            \begin{tabular}{cc}
            \includegraphics[height=0.3\textwidth]{Img/tyer/ATwoFingers.png}
            %
            &
            %
            \includegraphics[height=0.3\textwidth]{Img/tyer/BLookingForRopeEnd.png}
            \end{tabular}
            \caption{Left: Subject A holds the rope with 2 fingers. Right: Subject B caught the rope end.}
            \label{fig:ABExamples}
        \end{figure}

        I implemented a procedure that finds the rope end in an image using the connected components algorithm (see Algorithm~\ref{alg:ConnectedComponents}). The rope end is found in the depth image, which makes the whole procedure invariant to the color of the rope. However, the rope segmentation from the depth image is prone to errors if the rope is twisted and shiny (see Section~\ref{sec:AvailableRopes}. Two example images from a successful knot-tying are shown in Figure~\ref{fig:R1R4ExampleImgs}.

        \begin{figure}[h]
            \centering
            \begin{tabular}{cc}
            \includegraphics[height=0.3\textwidth]{Img/tyer/R1KnotTightening.png}
            &
            \includegraphics[height=0.3\textwidth]{Img/tyer/R4KnotTightening.png}

            \end{tabular}
            \caption{Left: Tightening the knot on the rope R1, Right: The knot made on the rope R4.}
            \label{fig:R1R4ExampleImgs}
        \end{figure}

        Moreover, I used the feedback from the force sensor to determine that the knot has been already tightened. In that case, further stretching of the rope is stopped.

        Further work could focus on making the rope end detection better. First, the code involving image processing could be made faster by for instance rewriting the Python code into \Cplusplus. Second, the information about the color of the rope could be combined with the depth information to improve the rope segmentation procedure. In addition, further work could focus on distinguishing the case when the rope end was successfully caught from the case when it was not. The finding of the rope end and the catching of it could be then repeated if necessary.

    \subsection{Ribbon manipulation}
        Based on the observation of a human rhythmic gymnast, I developed a procedure that allows the \CloPeMa\/ robot to catch a swinging pole hanging on a ribbon. The task involves mathematical modeling of the swinging pole and ribbon and exploring the capabilities of the gripper such as its maximum closing speed. The light and proximity sensors placed in the robot gripper were used to detect the presence of the pole and to determine whether the pole was caught well or not. Figure~\ref{fig:HumanAndRobotGymnastPoleCatch}, left side shows the human rhythmic gymnast that caught a swinging pole and Figure~\ref{fig:HumanAndRobotGymnastPoleCatch}, right side shows the \CloPeMa\/ robot performing the same.

        \begin{figure}[h]
            \centering
            \begin{tabular}{cc}
            \includegraphics[height=0.39\textwidth]{Img/ribbon/HumanGymnastPendulum.png}
            %
            &
            %
            \includegraphics[height=0.39\textwidth]{Img/ribbon/PoleCaught.png}
            \end{tabular}
            \caption{Left: The human rhythmic gymnast catching a swinging pole. Right: The robotic gymnast catching a swinging pole.}
            \label{fig:HumanAndRobotGymnastPoleCatch}
        \end{figure}

        I also investigated the possibilities of performing fast motions with the \CloPeMa\/ robot. The aim was to mimic a human rhythmic gymnast performing fast motions with the ribbon (see Figure~\ref{fig:HumanAndRobotGymnastShapes}, left side) thus forming shapes that are nice to watch. Figure~\ref{fig:HumanAndRobotGymnastShapes}, right side shows the robotic counterpart doing the same.

        \begin{figure}[h]
            \centering
            \begin{tabular}{cc}
            \includegraphics[height=0.39\textwidth]{Img/ribbon/HumanGymnastShapes.png}
            %
            &
            %
            \includegraphics[height=0.39\textwidth]{Img/ribbon/RobotGymnastShapes.png}
            \end{tabular}
            \caption{Left: The human rhythmic gymnast performing fast motions with the ribbon. Right: Robotic gymnast performing fast motions with the ribbon.}
            \label{fig:HumanAndRobotGymnastShapes}
        \end{figure}

        However, the fact that the maximum speed of the robot is limited to 20\% when it is operated through ROS does not allow the ribbon to be swung fast enough to form a visually nice shape. The results obtained when operating the robot through a teach pendant (thus reaching the maximum robot speed) were better. Yet operating the robot at its maximum speed in an unskilled manner for longer periods of time might cause damage.

    \subsection{Regrasping a rope}
        I successfully designed a scenario in which the \CloPeMa\/ robot regrasps a rope from one gripper to the other and back. The procedure is fully automated. The proximity sensor is used to detect the presence of the rope in the gripper. To make the rope detection process more robust so that it can handle ropes of different thickness, the gripper closes when a peak in the output of the proximity sensor passes (I do not use a simple thresholding).

        The regrasping procedure was recorded in the video that is called \textit{RegraspRope.mpg} and can be found on the attached CD. I have also taken a few screen shots from the procedure to illustrate it better. They are shown in Figure~\ref{fig:RegraspingProcess}.

        \begin{figure}[h]
            \centering
            \begin{tabular}{c|c}
            \includegraphics[width=0.4\textwidth]{Img/regrasping/RegraspInit.png}
            &
            \includegraphics[width=0.4\textwidth]{Img/regrasping/Regrasping.png} \\
            1 & 2 \\
            \hline
            \includegraphics[width=0.4\textwidth]{Img/regrasping/RopeDownLeft.png}
            &
            \includegraphics[width=0.4\textwidth]{Img/regrasping/RegraspingRight.png} \\
            3 & 4 \\
            \hline
            \includegraphics[width=0.4\textwidth]{Img/regrasping/RopeDownRight.png}
            &
            \includegraphics[width=0.4\textwidth]{Img/regrasping/SwitchArmsRight.png} \\
            5 & 6 \\

            \end{tabular}
            \caption{1: The initial pose. 2: The rope caught with the right gripper. 3: The rope released from the left gripper. 4: The rope caught with the left gripper. 5: The rope released from the right gripper. 6: Back to the initial pose.}
            \label{fig:RegraspingProcess}
        \end{figure}

        Further work could improve the release of the rope. The present solution does not allow regrasping of the rope many times (see the difference between 1 and 6 in Figure~\ref{fig:RegraspingProcess}), since it is not sure on which side of the gripper the rope falls down. Therefore, it is not possible to ensure that the rope is unwrapped correctly. This issue can be solved by avoiding the release of the rope directly above the lower gripper. The rope should be released a bit to the side, so that it falls to a predictable side of the lower gripper.

    \subsection{Documentation of the developed code}
        I made a documentation of the code that I wrote. The full version in HTML (see screen-shot in Figure~\ref{fig:DocHTML}) and pdf can be found on the attached CD.

        \begin{figure}[h!]
        \includegraphics[width=0.5\textwidth]{Img/conclusion/DocHTML.png}
        \centering
        \caption{HTML documentation of the source code.}
        \label{fig:DocHTML}
        \end{figure}

        A part of the developed code are the so called managers. These are classes that simplify the work with the \CloPeMa\/ robot. \emph{MoveManager} and \emph{GripperManager} provide the functionality connected with the movement of the robot and its grippers. \emph{ForceManager}, \emph{CameraManager} and \emph{ProximityManager} encapsulate methods connected with the force/torque sensor, Kinect sensor and the light and proximity sensors in the grippers. These classes could be the entry point for somebody new who wants to start working with the robot.



\clearpage 